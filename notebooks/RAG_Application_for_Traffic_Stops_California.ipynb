{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LehUyHl8yo8-",
    "outputId": "f4d42312-02eb-4e3b-c29d-f053e80e4955"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m69.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.3/31.3 MB\u001b[0m \u001b[31m57.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m110.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.2/45.2 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m95.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m81.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m85.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m52.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m85.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "# Install required packages (run once)\n",
    "!pip install langchain langchain-community langchain-huggingface faiss-cpu sentence-transformers huggingface-hub accelerate transformers streamlit --quiet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R8au_8ef_ztU",
    "outputId": "b9ac306b-5081-41a0-cceb-6c56d4f1eb78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.53.2)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.33.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.1)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.5)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.7.14)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers torch\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "id": "UPkBg0nmywks"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from transformers import pipeline\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "class RAGApp:\n",
    "    def __init__(self, csv_path):\n",
    "        self.df = pd.read_csv(csv_path, low_memory=False)\n",
    "        print(\"Total rows before sampling:\", len(self.df))\n",
    "\n",
    "        # Build context for each row\n",
    "        self.df['context'] = self.df.apply(self.build_context, axis=1)\n",
    "        self.df = self.df[self.df['context'] != \"Context unavailable.\"]\n",
    "        print(\"Empty contexts:\", (self.df['context'] == \"Context unavailable.\").sum())\n",
    "\n",
    "        # Sample for performance\n",
    "        sampled_df = self.df.sample(n=min(2000, len(self.df)), random_state=42)\n",
    "\n",
    "        # Create documents\n",
    "        self.docs = [Document(page_content=row['context']) for _, row in sampled_df.iterrows()]\n",
    "        print(\"Total documents:\", len(self.docs))\n",
    "\n",
    "        # Split into chunks\n",
    "        self.splitter = CharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "        self.split_docs = self.splitter.split_documents(self.docs)\n",
    "        print(\"Total chunks after splitting:\", len(self.split_docs))\n",
    "\n",
    "        # Use local embedding model\n",
    "        embed_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "        self.vectorstore = FAISS.from_documents(self.split_docs, embedding=embed_model)\n",
    "        self.retriever = self.vectorstore.as_retriever()\n",
    "\n",
    "        # Load local LLM (GPT2)\n",
    "        generator = pipeline(\"text-generation\", model=\"gpt2\", max_new_tokens=100)\n",
    "        self.llm = HuggingFacePipeline(pipeline=generator)\n",
    "\n",
    "        # RetrievalQA chain\n",
    "        self.qa_chain = RetrievalQA.from_chain_type(llm=self.llm, retriever=self.retriever)\n",
    "\n",
    "    @staticmethod\n",
    "    def build_context(row):\n",
    "        try:\n",
    "            date = row['DATE_OF_STOP']\n",
    "            time = row['TIME_OF_STOP']\n",
    "            city = row.get('CLOSEST_CITY', 'Unknown')\n",
    "\n",
    "            ticket_count = row.get('ROS_CITATION_CDS', 0)\n",
    "            warning_count = row.get('ROS_WARNING_CDS', 0)\n",
    "\n",
    "            gender_cols = [\n",
    "                'G_MALE', 'G_FEMALE', 'G_TRANSGENDER_MAN',\n",
    "                'G_TRANSGENDER_WOMAN', 'G_GENDER_NONCONFORMING', 'G_MULTIGENDER'\n",
    "            ]\n",
    "            gender = 'Unknown'\n",
    "            for col in gender_cols:\n",
    "                if col in row and row[col] == 1:\n",
    "                    gender = col.replace('G_', '').replace('_', ' ').title()\n",
    "                    break\n",
    "\n",
    "            person_type = 'Student' if row.get('STOP_STUDENT', 0) == 1 else 'Non-student'\n",
    "\n",
    "            return (f\"On {date} at {time}, a {person_type} {gender} was stopped in {city}. \"\n",
    "                    f\"Tickets issued: {ticket_count}, Warnings issued: {warning_count}.\")\n",
    "        except Exception:\n",
    "            return \"Context unavailable.\"\n",
    "\n",
    "    def query(self, question):\n",
    "        return self.qa_chain.invoke({\"query\": question})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 388,
     "referenced_widgets": [
      "b42cec78ce034439b28fc91e8d378f3d",
      "4fd47e3f44f2418a8b216e70cfa3bec3",
      "23d105b178e54b6db3768450f754f4f2",
      "a391071ef754492fa23ab9513b76f4f8",
      "d31c4e549edd4d49b9ccd4c5bd10e7b1",
      "071515006c244e8b94d612c119a17980",
      "93e07953f19b4e399cec433d915b583a",
      "deb9c639f84644c3a5b32520231af4c6",
      "e2a751fa706f40e1b1e046b17ccbad6b",
      "6bbcc339f4e94730b48c90e036fd740e",
      "4126bc4d36d4438fab2565eeda9018a3",
      "89e24eb4509f43c1b375ce214566c0b8",
      "ebdc88d7b8964791811c43fdf138b509",
      "a6533bf0c3254a0a9223e886759c1f8a",
      "e19379563c7f4f64906b469123854796",
      "fd2b8dc6364f46a189a137e30b3b983e",
      "544f85c24c714912ac207f6997c12e85",
      "89c363b2bf61411b833cafa58d7f1efc",
      "5677ba56290f4c4a940d2d2e42fbf8ca",
      "3acd2d1b315a46c4af3c7fe860b8a753",
      "ff7435d469f64cca98a895bfabeac6d1",
      "652e4f3268394b6293d37acfee7f6d70",
      "a2ac538a79d54f39a730d4d16d3c7698",
      "c6a6a99ef1954ca69f22a5fdc9ab7ea4",
      "5f282d1eaa4348039a4d3fe94d891c65",
      "183b4a0b59f34b9e8716a0c1a91e7e7b",
      "377e755338f149b8b3e1307253b27356",
      "fbaa5199894e4ce1823afaf669b79905",
      "bc49368e8a2e4e8181e2aab237ef784b",
      "4e8ef4720ac44244bd8fda41cf9b00fd",
      "9a42ac93721d4fb399e0373001e0b888",
      "2057bc60849c4c27a75a4df4cdb94953",
      "bac0625b89874d11850ac58742776cb5",
      "d1413c0ad08b4a28b3913b572bf239e1",
      "c180c73a01dc4af99e1c3f10a2e9834b",
      "344d0e8d159148f7836d03bf61cd683f",
      "a9c2850df16849ed93ee415b22c074ed",
      "af48198d42544400b3c8caecd444d928",
      "7fd88d6d084d47d19b0739538813190d",
      "54396035142043e881743dfcc94a60e0",
      "c79452d738604ae0b7ed6884c85a9b9b",
      "76057aa1eb97407eb421c205eec8b8ca",
      "e802e9edaa1a484785b6c28cd31580ca",
      "6999ecc2c76e408fb33f56e91c1c60d7",
      "06971994d6984aefaae2ef771e59e7b1",
      "fb23f24eeadb41e3a95729f999e6803f",
      "b6e383f348854293bb13b5ef1cb86a5b",
      "b1c78657bb0a4124b0109411f387607b",
      "e0b263017ac84b8583b01f691f605712",
      "8950e672a91e4148a8c744d59520e60e",
      "6221e1a92a194645bbfac77c9c651230",
      "17cf8433c4f1466e96e437e4e85034b9",
      "e6e2fcf11c274380ae478e70c00481e2",
      "4bb06437626347a18040b72b44e91328",
      "97859c51ad7745178d17877147b450b4",
      "fd71b71fe1e24ad38f8c349d1c44aa07",
      "68b8eb139aac47d6a5d7b7deef80c5df",
      "e261bac971324968a87d341f039f5f5e",
      "4d03e04816ec4068ab817f5bb069e816",
      "0e43bea8fce74cf291b03fbf3db67f3e",
      "c79a22d0e8a24766bb12390669b81ecc",
      "47c98c5d8e0541c5b026f75596981c88",
      "ffbc03c180034d13817b745840adf09a",
      "a151d1bf959a4976aec4b2aa75957048",
      "0e2549ecef044ed48a12084769612d88",
      "4709edbacea440d5b72e53a8be600b23",
      "2a229fc79c0b4344ad3756ff0de741d0",
      "37829a5638e24b90b365224f8940d641",
      "efc7b71f83f547a4844931a29ebc4cdc",
      "53bd0950642049f79f9f89418be98ba5",
      "bc90656de8674a11a0dd65eed9242f8c",
      "0701936649944892bae5e942dd417458",
      "40d99c6fea2c423cae214ff460232ace",
      "2d6c36f1062d4859b681ee0af0318373",
      "76c5353a43124d5e8e0a0b46710b52d6",
      "e3af827eb9a64799890e0e68a8ebed7d",
      "f3af200fe52c446999214de516a2320d"
     ]
    },
    "id": "CCYc7kRZy6_H",
    "outputId": "7cfffafa-3e8d-479f-80f8-de79ae226cb4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows before sampling: 70211\n",
      "Empty contexts: 0\n",
      "Total documents: 2000\n",
      "Total chunks after splitting: 2000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b42cec78ce034439b28fc91e8d378f3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89e24eb4509f43c1b375ce214566c0b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2ac538a79d54f39a730d4d16d3c7698",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1413c0ad08b4a28b3913b572bf239e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06971994d6984aefaae2ef771e59e7b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd71b71fe1e24ad38f8c349d1c44aa07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a229fc79c0b4344ad3756ff0de741d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "/tmp/ipython-input-80-1481757365.py:39: LangChainDeprecationWarning: The class `HuggingFacePipeline` was deprecated in LangChain 0.0.37 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFacePipeline``.\n",
      "  self.llm = HuggingFacePipeline(pipeline=generator)\n"
     ]
    }
   ],
   "source": [
    "rag = RAGApp(\"RIPA_2023_Merged_Cities.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ryRW_B6dCqEv",
    "outputId": "1485379a-fdf1-4361-819b-bc14577587ad"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "On 2023-10-20 at 20:54:00, a Non-student Male was stopped in EL CENTRO. Tickets issued: 54167, Warnings issued: nan.\n",
      "\n",
      "On 2023-12-02 at 18:42:00, a Non-student Male was stopped in EL CENTRO. Tickets issued: 42127, 54101, 54657, Warnings issued: nan.\n",
      "\n",
      "On 2023-10-10 at 12:50:00, a Non-student Male was stopped in EL CENTRO. Tickets issued: nan, Warnings issued: 54167.\n",
      "\n",
      "On 2023-11-25 at 13:20:00, a Non-student Female was stopped in BLUE LAKE. Tickets issued: nan, Warnings issued: 54106.\n",
      "\n",
      "Question: How many stops were there on 25-05-2023\n",
      "Helpful Answer:\n",
      "\n",
      "On 25-05-2023, a Non-student Female was stopped in EL CENTRO. Tickets issued: 54127, 54101, 56806, Warnings issued: nan.\n",
      "\n",
      "On 25-05-2023, a Non-student Female was stopped in BLUE LAKE. Tickets issued: nan, Warnings issued: 54107.\n",
      "\n",
      "On 25-05-2023, a Non-student Female was stopped in BLUE LAKE. Tickets\n"
     ]
    }
   ],
   "source": [
    "response = rag.query(\"How many stops were there on 25-05-2023\")\n",
    "print(response[\"result\"])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
